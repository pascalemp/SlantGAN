{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SlantGAN - A simple implementation of a basic GAN</h1>\n",
    "\n",
    "*Given a 2x2 matrix consisting of real values in the interval [0,1] we aim to be able to deduce\n",
    "a *'slanted person'* such that they have values **ONLY** in the leading diagnonal of the matrix (from the upper left side.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random \n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing function\n",
    "def view_samples(samples, m, n):\n",
    "    fig, axes = plt.subplots(figsize=(10, 10), nrows=m, ncols=n, sharey=True, sharex=True)\n",
    "    for ax, img in zip(axes.flatten(), samples):\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        im = ax.imshow(1-img.reshape((2,2)), cmap='Greys_r')  \n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Examples of 'Faces' </h2>\n",
    "\n",
    "*By 'slanted person' we are abstracting the idea of an image that has a distorted face in it, for example:*\n",
    "\n",
    "<img src=\"images/slant.png\" width=250 height=250 />\n",
    "\n",
    "*The above image can be represented as a 2x2 matrix, as displayed below:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAACHCAYAAAASnYMFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA25JREFUeJzt27FKI1EUgOHMuoKljZ2wjY1gEYjvjw+QgA9g4YLdWvgGd8utTLPOjPzzfe3A5RAONz8JM40xdgAAZT/WHgAAYG6CBwDIEzwAQJ7gAQDyBA8AkPfz3MNpmjb3CtfhcFh7hMWdTqf3McbNXOfbo77X19fd+/v7NNf5W9yh/X6/9giLe35+nvUuuri4GJeXl3Md/y09PDysPcKizt1F07nX0rd4yWzxNf1pmk5jjMcZz9/ch7q1PXp8fNwdj0fB84U+Pj7WHmFx19fXs95FV1dX4/b2dq7jv6WXl5e1R1jUubvIX1oAQJ7gAQDyBA8AkCd4AIA8wQMA5AkeACBP8AAAeYIHAMgTPABAnuABAPIEDwCQJ3gAgDzBAwDkCR4AIE/wAAB5ggcAyBM8AECe4AEA8gQPAJAneACAPMEDAOQJHgAgT/AAAHmCBwDIEzwAQJ7gAQDyBA8AkCd4AIA8wQMA5AkeACBP8AAAeYIHAMgTPABAnuABAPIEDwCQJ3gAgDzBAwDkCR4AIE/wAAB5ggcAyBM8AECe4AEA8gQPAJAneACAPMEDAOQJHgAgT/AAAHmCBwDIEzwAQJ7gAQDyBA8AkCd4AIA8wQMA5AkeACBP8AAAeYIHAMgTPABAnuABAPIEDwCQ9/Pcw8PhsDsej0vN8i1M07T2CDn7/X739PS09hiLuru7W3uERb29vc16/hbvoq3t0BLu7+83dxf5TvvHLzwAQJ7gAQDyBA8AkCd4AIA8wQMA5AkeACBP8AAAeYIHAMgTPABAnuABAPIEDwCQJ3gAgDzBAwDkCR4AIE/wAAB5ggcAyBM8AECe4AEA8gQPAJAneACAPMEDAOQJHgAgT/AAAHmCBwDIEzwAQJ7gAQDyBA8AkCd4AIA8wQMA5AkeACBP8AAAeYIHAMgTPABAnuABAPIEDwCQJ3gAgDzBAwDkCR4AIE/wAAB5ggcAyBM8AECe4AEA8gQPAJAneACAPMEDAOQJHgAgT/AAAHmCBwDIEzwAQJ7gAQDyBA8AkCd4AIA8wQMA5AkeACBP8AAAeYIHAMgTPABAnuABAPIEDwCQJ3gAgLxpjPH5w2n6s9vtfi83Div5Nca4metwe7QJdoivYI/4X5/u0NngAQAo8JcWAJAneACAPMEDAOQJHgAgT/AAAHl/ASQQbBIsJMXhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Examples of faces\n",
    "faces = [np.array([1,0,0,1]),\n",
    "         np.array([0.9,0.1,0.2,0.8]),\n",
    "         np.array([0.9,0.2,0.1,0.8]),\n",
    "         np.array([0.8,0.1,0.2,0.9]),\n",
    "         np.array([0.8,0.2,0.1,0.9])]\n",
    "    \n",
    "_ = view_samples(faces, 1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Examples of Random Noise </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAACHCAYAAAASnYMFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA61JREFUeJzt27FNI0EYhuGd04kIEsymnGsAmoEOoAIaoBACeiHwEtAAmAjp3MNcA2cnd7Oz+vw86Uizv6XZ9SuvXGqtAwBAsh+9BwAAaE3wAADxBA8AEE/wAADxBA8AEO/nocVSytH9hevq6qr3CLN7e3vb1VrHVvtfXFzU9XrdavtFmqap9wizq7WWVnufnZ3VcWx2RBfp/Py89wizm6ap6bPo9PS0rlarVtsv0rHdN5+fn8Nut/vrs+hg8Byj19fX3iPM7uTkZNty//V6PWw2m5aXWJxSmn33H6VxHIenp6feY8zq9va29wizK6U0fRatVqvh8fGx5SUW5/7+vvcIs7q5udm75pUWABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABBP8AAA8QQPABDv56HF6+vrYbPZzDXLIry8vPQeIc77+/tweXnZe4xZHdvn/f7+brr/x8fHcHd31/QaS/P8/Nx7hDhfX1/Dw8ND7zFmNU1T7xFmtd1u9675hQcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4ggcAiCd4AIB4pda6f7GU38MwbOcbh05+1VrHVps7R0fBGeJ/cI74V3vP0MHgAQBI4JUWABBP8AAA8QQPABBP8AAA8QQPABDvD8FkYpoWvHrdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Examples of noisy images\n",
    "noise = [np.random.randn(2,2) for i in range(20)]\n",
    "\n",
    "def generate_random_image():\n",
    "    return [np.random.random(), np.random.random(), np.random.random(), np.random.random()]\n",
    "\n",
    "_ = view_samples(noise, 1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> The Discriminator Network </h2>\n",
    "\n",
    "*The 'Discriminator' Network architecture and backpropagation derivation is displayed below:*\n",
    "\n",
    "<img src=\"images/discriminator.png\" width=1000 height=1200 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator():\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialise all weights randomly to begin with\n",
    "        self.weights = np.array([np.random.normal() for i in range(4)])\n",
    "        \n",
    "        # Initialise one random bias to begin with.\n",
    "        self.bias = np.random.normal()\n",
    "        \n",
    "    # Forward pass for a given image returns sigmoid(weights_matrix * image_matrix + bias_value) \n",
    "    def forward(self, image):\n",
    "        return sigmoid(np.dot(image, self.weights) + self.bias)\n",
    "    \n",
    "    # Derivatives for an 'image' i.e. a test image\n",
    "    def image_derivatives(self, image):\n",
    "        # Get the current prediction\n",
    "        prediction = self.forward(image)\n",
    "        # Get the weight and bias derivatives\n",
    "        deriv_weights = -image * (1 - prediction)\n",
    "        deriv_bias = -(1 - prediction)\n",
    "        return deriv_weights, deriv_bias\n",
    "    \n",
    "    # Derivatives for 'noise' i.e. an image generated by our Generator Net\n",
    "    def noise_derivatives(self, noise):\n",
    "        # Get the current prediction\n",
    "        prediction = self.forward(noise)\n",
    "        # Get the weight and bias derivatives\n",
    "        deriv_weights = noise * prediction\n",
    "        deriv_bias = prediction\n",
    "        return deriv_weights, deriv_bias\n",
    "    \n",
    "    # Update the weights for an 'image' \n",
    "    def image_update(self, x):\n",
    "        derivatives = self.image_derivatives(x)\n",
    "        self.weights -= learning_rate * derivatives[0]\n",
    "        self.bias -= learning_rate * derivatives[1]\n",
    "    \n",
    "    # Update the weights for 'noise' - note the different loss function to the \n",
    "    # image_update.\n",
    "    def noise_update(self, noise):\n",
    "        derivs = self.noise_derivatives(noise)\n",
    "        self.weights -= learning_rate * derivs[0]\n",
    "        self.bias -= learning_rate * derivs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> The Generator Network </h2>\n",
    "\n",
    "*The 'Generator' Network architecture and backpropagation derivation is displayed below:*\n",
    "\n",
    "<img src=\"images/generator.png\" width=1000 height=1200 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator():\n",
    "    \n",
    "    def __init__(self):\n",
    "                \n",
    "        # Initialise all weights and biases randomly to begin with\n",
    "        self.weights = np.array([np.random.normal() for i in range(4)])\n",
    "        self.biases = np.array([np.random.normal() for i in range(4)])\n",
    "        \n",
    "    def forward(self, z):\n",
    "        # Current output image, which is generated each time from\n",
    "        # the z value that is updated by the weights and the biases.\n",
    "        return sigmoid(z * self.weights + self.biases)    \n",
    "    \n",
    "    # To work out the derivatives through backpropagation for the \n",
    "    # generator network, we need the weights associated with\n",
    "    # the discriminator.\n",
    "    def derivatives(self, z, discriminator):\n",
    "        \n",
    "        d_weights = discriminator.weights\n",
    "        \n",
    "        x = self.forward(z)\n",
    "        y = discriminator.forward(x)\n",
    "        \n",
    "        # This 'factor' variable is just a nicer way of representing \n",
    "        # the formula in a re-useable part, as opposed to writing it\n",
    "        # out twice for the derivative weights and biases separately.\n",
    "        \n",
    "        factor = -(1-y) * d_weights * x *(1-x)\n",
    "        deriv_weights = factor * z\n",
    "        deriv_bias = factor\n",
    "        \n",
    "        return deriv_weights, deriv_bias\n",
    "    \n",
    "    # Update the Generator weights based on the current z-value and \n",
    "    # the discriminator weights.\n",
    "    def update(self, z, discriminator):\n",
    "        ders = self.derivatives(z, discriminator)\n",
    "        self.weights -= learning_rate * ders[0]\n",
    "        self.biases -= learning_rate * ders[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Initialisation\n",
    "epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "# An array of 'faces' i.e. those that constitute a 'true'\n",
    "# face.\n",
    "faces = [np.array([1,0,0,1]),\n",
    "         np.array([0.9,0.1,0.2,0.8]),\n",
    "         np.array([0.9,0.2,0.1,0.8]),\n",
    "         np.array([0.8,0.1,0.2,0.9]),\n",
    "         np.array([0.8,0.2,0.1,0.9])]\n",
    "\n",
    "# Instantiate both networks\n",
    "G = Generator()\n",
    "D = Discriminator()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # We pass a 'noise' image to the discriminator which is generated by the\n",
    "    # generator, followed by a 'real face' and we do this for all 'real' faces\n",
    "    # each epoch.\n",
    "    \n",
    "    for face in faces:\n",
    "    \n",
    "        # Pick a random number to generate a fake face\n",
    "        z = random.rand()\n",
    "\n",
    "        # Generate a fake face\n",
    "        noise = G.forward(z)\n",
    "        \n",
    "        # Update the discriminator weights from the fake face\n",
    "        D.noise_update(noise)\n",
    "    \n",
    "        # Update the generator weights from the fake face\n",
    "        G.update(z, D)\n",
    "        \n",
    "        # Update the discriminator weights from the real face\n",
    "        D.image_update(face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>'Faces' Created by our trained Generator:</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87130456 0.04903192 0.09053415 0.93312271]\n",
      "[0.96243707 0.01905462 0.0617396  0.96620246]\n",
      "[0.93691385 0.02816259 0.07232776 0.95517193]\n",
      "[0.96774169 0.0170082  0.05895782 0.96887126]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAACHCAYAAAASnYMFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA1hJREFUeJzt3DFO40AYgNGMlQPQUO8RgMD9WxpyB7benICC2XIr0rC20Zf3WkujX8po/MWRM+acBwCAsmXvAQAA1iZ4AIA8wQMA5AkeACBP8AAAecdrF5dlmctyW030+Pi49wibO5/Plznn/VrrjzFu7lXA5+fnvUfY1Pv7++FyuYy11h9jzDFWW/5HOp1Oe4+wOWfR/+cs+mdcey39eDzOu7u71Qb7iS6Xy94jbG6McZ5zvqy4/s3drD4/P/ceYVMvLy+Ht7e31T7kZVnm8Xj1+1nOx8fH3iNsbouzaK21f6pb++uZa2fRbT2+AQBukuABAPIEDwCQJ3gAgDzBAwDkCR4AIE/wAAB5ggcAyBM8AECe4AEA8gQPAJAneACAPMEDAOQJHgAgT/AAAHmCBwDIEzwAQJ7gAQDyBA8AkCd4AIA8wQMA5AkeACBP8AAAeYIHAMgTPABAnuABAPIEDwCQJ3gAgDzBAwDkCR4AIE/wAAB5ggcAyBM8AECe4AEA8gQPAJAneACAPMEDAOQJHgAgT/AAAHmCBwDIEzwAQJ7gAQDyBA8AkCd4AIA8wQMA5AkeACBP8AAAeYIHAMgTPABAnuABAPIEDwCQJ3gAgDzBAwDkCR4AIE/wAAB5ggcAyBM8AECe4AEA8gQPAJB3vHbx4eHh8Pr6utUsP8IYY+8Rck6nk33Etzw9PdlDfJuz6LZ5wgMA5AkeACBP8AAAeYIHAMgTPABAnuABAPIEDwCQJ3gAgDzBAwDkCR4AIE/wAAB5ggcAyBM8AECe4AEA8gQPAJAneACAPMEDAOQJHgAgT/AAAHmCBwDIEzwAQJ7gAQDyBA8AkCd4AIA8wQMA5AkeACBP8AAAeYIHAMgTPABAnuABAPIEDwCQJ3gAgDzBAwDkCR4AIE/wAAB5ggcAyBM8AECe4AEA8gQPAJAneACAPMEDAOQJHgAgT/AAAHmCBwDIEzwAQJ7gAQDyBA8AkCd4AIA8wQMA5AkeACBP8AAAeYIHAMgTPABAnuABAPIEDwCQJ3gAgDzBAwDkCR4AIE/wAAB5ggcAyBtzzq8vjvHncDj83m4cdvJrznm/1uL20U2wh/gf7CO+68s9dDV4AAAK/KQFAOQJHgAgT/AAAHmCBwDIEzwAQN5fh5Ror5ESxmIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generated_images = []\n",
    "for i in range(4):\n",
    "    z = random.random()\n",
    "    generated_image = G.forward(z)\n",
    "    generated_images.append(generated_image)\n",
    "_ = view_samples(generated_images, 1, 4)\n",
    "for i in generated_images:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Acknolwedgements</h1>\n",
    "\n",
    "*Implementation based on the fantastic work of Luis Guiserrano:* https://github.com/luisguiserrano/gans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-venv",
   "language": "python",
   "name": "ai-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
